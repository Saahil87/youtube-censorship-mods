{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7747fa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b377c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "catColumns = ['AntiSJW','AntiTheist', 'Black', 'Conspiracy', 'LGBT',\n",
    "       'LateNightTalkShow', 'Libertarian', 'MRA', 'PartisanLeft', 'PartisanRight', 'Politician', 'QAnon', \n",
    "       'ReligiousConservative', 'SocialJustice', 'Socialist', 'StateFunded',\n",
    "       'WhiteIdentitarian', \"C\", \"L\", \"R\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6846f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_feature(df, column_name):\n",
    "    minviews = min(df[column_name])\n",
    "    maxviews = max(df[column_name])\n",
    "    def feature_scaling(x):\n",
    "        return (x - minviews)/(maxviews - minviews)\n",
    "    df[f'scaled_{column_name}'] = df[column_name].apply(feature_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "df38bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(splitType, splitSize, relevantColumns):\n",
    "    dataPath = f\"{rootPath}/{splitType}/{splitSize}\"\n",
    "    train = pd.read_csv(f\"{dataPath}/X_train_bert.csv\", index_col=0)\n",
    "    Y_train = pd.read_csv(f\"{dataPath}/y_train.csv\", index_col=0)\n",
    "    test = pd.read_csv(f\"{dataPath}/X_test_bert.csv\", index_col=0)\n",
    "    Y_test = pd.read_csv(f\"{dataPath}/y_test.csv\", index_col=0)\n",
    "    train[list(dict(train.groupby(\"lr\").size()))] = pd.get_dummies(train[\"lr\"])\n",
    "    test[list(dict(test.groupby(\"lr\").size()))] = pd.get_dummies(test[\"lr\"])\n",
    "    train[list(dict(train.groupby(\"channelId\").size()))] = pd.get_dummies(train[\"channelId\"])\n",
    "    test[list(dict(test.groupby(\"channelId\").size()))] = pd.get_dummies(test[\"channelId\"])\n",
    "    X = train[relevantColumns].to_numpy()\n",
    "    y = np.array(list(Y_train[\"interesting_removal_2\"].astype(int)))\n",
    "    X_test = test[relevantColumns].to_numpy()\n",
    "    y_test = np.array(list(Y_test[\"interesting_removal_2\"].astype(int)))\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X, X_test, y, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "90ee4f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLabels():\n",
    "    EMBED_OUTPUT = 768\n",
    "    labels = []\n",
    "    for i in range(EMBED_OUTPUT):\n",
    "        labels.append(f\"embed_{i+1}\")\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b3358eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(model, x, y):\n",
    "    metric = {\n",
    "        \n",
    "    }\n",
    "    y_pred = model.predict(x)\n",
    "    metric[\"accuracy\"] = np.sum(y_pred == y)/y.shape[0]\n",
    "    metric[\"precision\"] = precision_score(y_pred, y)\n",
    "    metric[\"recall\"] = recall_score(y_pred, y)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3b65660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [\"rep\", \"even\"]\n",
    "sizes = [\"10\", \"50\", \"100\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b9e279be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevantColumns = catColumns\n",
    "relevantColumns = catColumns + generateLabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "075c12e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: rep\n",
      "Size: 10\n",
      "{'accuracy': 0.9996473906911142, 'precision': 0.9919354838709677, 'recall': 1.0}\n",
      "{'accuracy': 0.956338028169014, 'precision': 0.3548387096774194, 'recall': 0.5}\n",
      "Split: rep\n",
      "Size: 50\n",
      "{'accuracy': 0.9997179921037789, 'precision': 0.9965635738831615, 'recall': 0.9965635738831615}\n",
      "{'accuracy': 0.9625035241048774, 'precision': 0.4330708661417323, 'recall': 0.47413793103448276}\n",
      "Split: rep\n",
      "Size: 100\n",
      "{'accuracy': 0.9994359842075579, 'precision': 0.9939498703543648, 'recall': 0.9922346850733391}\n",
      "{'accuracy': 0.9641900465247427, 'precision': 0.4925373134328358, 'recall': 0.528}\n",
      "Split: even\n",
      "Size: 10\n",
      "{'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0}\n",
      "{'accuracy': 0.6896551724137931, 'precision': 0.7586206896551724, 'recall': 0.6666666666666666}\n",
      "Split: even\n",
      "Size: 50\n",
      "{'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0}\n",
      "{'accuracy': 0.8140350877192982, 'precision': 0.823943661971831, 'recall': 0.8068965517241379}\n",
      "Split: even\n",
      "Size: 100\n",
      "{'accuracy': 0.9991228070175439, 'precision': 1.0, 'recall': 0.9982486865148862}\n",
      "{'accuracy': 0.8192982456140351, 'precision': 0.8245614035087719, 'recall': 0.8159722222222222}\n"
     ]
    }
   ],
   "source": [
    "for split in splits:\n",
    "    for size in sizes:\n",
    "        X_train, X_test, y_train, y_test = getData(split, size, relevantColumns)\n",
    "#         clf = SVC(kernel='poly')\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-4, activation=\"relu\", hidden_layer_sizes=(160), random_state=1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_accuracy = evaluateModel(clf, X_train, y_train)\n",
    "        test_accuracy = evaluateModel(clf, X_test, y_test)\n",
    "        print(f\"Split: {split}\")\n",
    "        print(f\"Size: {size}\")\n",
    "        print(train_accuracy)\n",
    "        print(test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
